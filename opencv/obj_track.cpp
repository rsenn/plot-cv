// objectTrackingTutorial.cpp

// Written by  Kyle Hounslow 2013

#include <sstream>
#include <string>
#include <iostream>
// opencv
#include <opencv2/imgcodecs.hpp>
#include <opencv2/imgproc.hpp>
#include <opencv2/videoio.hpp>
#include <opencv2/highgui.hpp>
#include <opencv2/video.hpp>
//#include <opencv2/cv.hpp>
#include <opencv2/core.hpp>
#include <opencv2/core/ocl.hpp>
#include <opencv2/core/utility.hpp>

// C
#include <stdio.h>

//using namespace cv;
using namespace std;
// initial min and max HSV filter values.
// these will be changed using trackbars
int H_MIN = 0;
int H_MAX = 256;
int S_MIN = 0;
int S_MAX = 256;
int V_MIN = 0;
int V_MAX = 256;
// default capture width and height
const int FRAME_WIDTH = 640;
const int FRAME_HEIGHT = 480;
// max number of objects to be detected in frame
const int MAX_NUM_OBJECTS = 50;
// minimum and maximum object area
const int MIN_OBJECT_AREA = 20 * 20;
const int MAX_OBJECT_AREA = FRAME_HEIGHT * FRAME_WIDTH / 1.5;
// names that will appear at the top of each window
const string windowName = "Original Image";
const string windowName1 = "HSV Image";
const string windowName2 = "Thresholded Image";
const string windowName3 = "After Morphological Operations";
const string trackbarWindowName = "Trackbars";

void processVideoBg(char* videoFilename);
void trackObjectloop();
void createTrackbars();
void morphOps(cv::Mat& thresh);
void trackFilteredObject(int& x, int& y, cv::Mat cv::threshold, cv::Mat& cameraFeed);
void backFilter();
void backFilterImageBased();

// Global variables
cv::Mat frame;                   // current frame
cv::Mat fgMaskMOG2;              // fg mask fg mask generated by MOG2 method
cv::Ptr<cv::BackgroundSubtractor> pMOG2; // MOG2 Background subtractor
int keyboard;                    // input from keyboard
char sourceVideo[] = "source.avi";

#define M_MOG2 2
#define M_KNN 3

int medianBlurStrng = 5, BlurStrng = 3, SecondBlurStrng = 1;
int
nearestEvenInt(int to) {
  return (to % 2 != 0) ? to : (to + 1);
}
int
main(int argc, char* argv[]) {
  // trackObjectloop();
  // backFilter();
  backFilterImageBased();
  return EXIT_SUCCESS;
}

void
backFilterImageBased() {
  bool useCamera = false;
  string file = "source.avi";
  int m = true ? M_MOG2 : M_KNN;

  cv::VideoCapture cap;
  if(useCamera)
    cap.open(0);
  else
    cap.open(file);

  if(!cap.isOpened()) {
    cout << "can not open camera or video file" << endl;
    return;
  }

  cv::Mat frame, fgmask, fgimg;
  cv::Mat bgImg = cv::imread("bgimg.jpg");
  cap >> frame;
  fgimg.create(frame.size(), frame.type());
  cv::Ptr<BackgroundSubtractorKNN> knn = cv::createBackgroundSubtractorKNN();
  cv::Ptr<cv::BackgroundSubtractorMOG2> mog2 = cv::createBackgroundSubtractorMOG2();
  cv::resize(bgImg, bgImg, frame.size());

  cv::namedWindow("Params", cv::WINDOW_NORMAL);
  cv::createTrackbar("cv::medianBlur", "Params", &medianBlurStrng, 35);
  cv::createTrackbar("PrevBlur", "Params", &BlurStrng, 10);
  cv::createTrackbar("PostBlur", "Params", &SecondBlurStrng, 10);

  switch(m) {
    case M_KNN: knn->apply(frame, fgmask); break;

    case M_MOG2: mog2->apply(frame, fgmask); break;
  }
  bool running = true;
  while(running) {
    cap >> frame;
    if(frame.empty())
      break;

    int64 start = cv::getTickCount();

    // update the model
    switch(m) {
      case M_KNN: knn->apply(frame, fgmask); break;

      case M_MOG2: mog2->apply(frame, fgmask); break;
    }
    // Filter model
    cv::medianBlur(fgmask, fgmask, nearestEvenInt(medianBlurStrng));
    cv::blur(fgmask, fgmask, cv::Size(BlurStrng + 1, BlurStrng + 1));
    cv::threshold(fgmask, fgmask, 250, 255, cv::THRESH_BINARY);
    cv::blur(fgmask, fgmask, cv::Size(SecondBlurStrng + 1, SecondBlurStrng + 1));

    double fps = cv::getTickFrequency() / (cv::getTickCount() - start);
    std::cout << "FPS : " << fps << std::endl;
    std::cout << fgimg.size() << std::endl;
    fgimg.setTo(cv::Scalar::all(0));
    bgImg.copyTo(fgimg);
    frame.copyTo(fgimg, fgmask);

    cv::imshow("image", frame);
    cv::imshow("foreground mask", fgmask);
    cv::imshow("foreground image", fgimg);

    char key = (char)cv::waitKey(30);

    switch(key) {
      case 27: running = false; break;
      case 'm':
      case 'M':
        cv::ocl::setUseOpenCL(!ocl::useOpenCL());
        cout << "Switched to " << (cv::ocl::useOpenCL() ? "OpenCL enabled" : "CPU") << " mode\n";
        break;
    }
  }
}

void
backFilter() {
  // create GUI windows
  cv::namedWindow("Frame");
  cv::namedWindow("FG Mask MOG 2");

  // create Background Subtractor objects
  pMOG2 = cv::createBackgroundSubtractorMOG2(); // MOG2 approach
  processVideoBg(sourceVideo);

  // destroy GUI windows
  cv::destroyAllWindows();
}

void
trackObjectloop() {
  // some boolean variables for different functionality within this
  // program
  bool trackObjects = false;
  bool useMorphOps = false;
  // cv::Matrix to store each frame of the webcam feed
  cv::Mat cameraFeed;
  // matrix storage for HSV image
  cv::Mat HSV;
  // matrix storage for binary cv::threshold image
  cv::Mat cv::threshold;
  // x and y values for the location of the object
  int x = 0, y = 0;
  // create slider bars for HSV filtering
  createTrackbars();
  // video capture object to acquire webcam feed
  cv::VideoCapture capture;
  // open capture object at location zero (default location for webcam)
  capture.open(0);
  // set height and width of capture frame
  capture.set(cv::CAP_PROP_FRAME_WIDTH, FRAME_WIDTH);
  capture.set(cv::CAP_PROP_FRAME_HEIGHT, FRAME_HEIGHT);
  // start an infinite loop where webcam feed is copied to cameraFeed matrix
  // all of our operations will be performed within this loop
  while(1) {
    // store image to matrix
    capture.read(cameraFeed);
    // convert frame from BGR to HSV colorspace
    cv::cvtColor(cameraFeed, HSV, cv::COLOR_BGR2HSV);
    // filter HSV image between values and store filtered image to
    // cv::threshold matrix
    cv::inRange(HSV, cv::Scalar(H_MIN, S_MIN, V_MIN), cv::Scalar(H_MAX, S_MAX, V_MAX), cv::threshold);
    // perform morphological operations on thresholded image to eliminate noise
    // and emphasize the filtered object(s)
    if(useMorphOps)
      morphOps(cv::threshold);
    // pass in thresholded frame to our object tracking function
    // this function will return the x and y coordinates of the
    // filtered object
    if(trackObjects)
      trackFilteredObject(x, y, cv::threshold, cameraFeed);

    // show frames
    cv::imshow(windowName2, cv::threshold);
    cv::imshow(windowName, cameraFeed);
    cv::imshow(windowName1, HSV);

    // delay 30ms so that screen can refresh.
    // image will not appear without this cv::waitKey() command
    cv::waitKey(30);
  }
}

void
on_trackbar(int, void*) { // This function gets called whenever a
  // trackbar position is changed
}
string
intToString(int number) {

  std::stringstream ss;
  ss << number;
  return ss.str();
}
void
createTrackbars() {
  // create window for trackbars

  cv::namedWindow(trackbarWindowName, 0);
  // create memory to store trackbar name on window
  char TrackbarName[50];
  sprintf(TrackbarName, "H_MIN", H_MIN);
  sprintf(TrackbarName, "H_MAX", H_MAX);
  sprintf(TrackbarName, "S_MIN", S_MIN);
  sprintf(TrackbarName, "S_MAX", S_MAX);
  sprintf(TrackbarName, "V_MIN", V_MIN);
  sprintf(TrackbarName, "V_MAX", V_MAX);
  // create trackbars and insert them into window
  // 3 parameters are: the address of the variable that is changing when the trackbar is
  // moved(eg.H_LOW), the max value the trackbar can move (eg. H_HIGH), and the function that is
  // called whenever the trackbar is moved(eg. on_trackbar)
  //                                  ---->    ---->     ---->
  cv::createTrackbar("H_MIN", trackbarWindowName, &H_MIN, H_MAX, on_trackbar);
  cv::createTrackbar("H_MAX", trackbarWindowName, &H_MAX, H_MAX, on_trackbar);
  cv::createTrackbar("S_MIN", trackbarWindowName, &S_MIN, S_MAX, on_trackbar);
  cv::createTrackbar("S_MAX", trackbarWindowName, &S_MAX, S_MAX, on_trackbar);
  cv::createTrackbar("V_MIN", trackbarWindowName, &V_MIN, V_MAX, on_trackbar);
  cv::createTrackbar("V_MAX", trackbarWindowName, &V_MAX, V_MAX, on_trackbar);
}
void
drawObject(int x, int y, cv::Mat& frame) {

  // use some of the openCV drawing functions to draw crosshairs
  // on your tracked image!

  // UPDATE:JUNE 18TH, 2013
  // added 'if' and 'else' statements to prevent
  // memory errors from writing off the screen (ie. (-25,-25) is not within the window!)

  cv::circle(frame, cv::Point(x, y), 20, cv::Scalar(0, 255, 0), 2);
  if(y - 25 > 0)
    cv::line(frame, cv::Point(x, y), cv::Point(x, y - 25), cv::Scalar(0, 255, 0), 2);
  else
    cv::line(frame, cv::Point(x, y), cv::Point(x, 0), cv::Scalar(0, 255, 0), 2);
  if(y + 25 < FRAME_HEIGHT)
    cv::line(frame, cv::Point(x, y), cv::Point(x, y + 25), cv::Scalar(0, 255, 0), 2);
  else
    cv::line(frame, cv::Point(x, y), cv::Point(x, FRAME_HEIGHT), cv::Scalar(0, 255, 0), 2);
  if(x - 25 > 0)
    cv::line(frame, cv::Point(x, y), cv::Point(x - 25, y), cv::Scalar(0, 255, 0), 2);
  else
    cv::line(frame, cv::Point(x, y), cv::Point(0, y), cv::Scalar(0, 255, 0), 2);
  if(x + 25 < FRAME_WIDTH)
    cv::line(frame, cv::Point(x, y), cv::Point(x + 25, y), cv::Scalar(0, 255, 0), 2);
  else
    cv::line(frame, cv::Point(x, y), cv::Point(FRAME_WIDTH, y), cv::Scalar(0, 255, 0), 2);

  cv::putText(frame, intToString(x) + "," + intToString(y), cv::Point(x, y + 30), 1, 1, cv::Scalar(0, 255, 0), 2);
}
void
morphOps(cv::Mat& thresh) {

  // create structuring element that will be used to "cv::dilate" and "cv::erode" image.
  // the element chosen here is a 3px by 3px rectangle

  cv::Mat erodeElement = cv::getStructuringElement(cv::MORPH_RECT, cv::Size(3, 3));
  // cv::dilate with larger element so make sure object is nicely visible
  cv::Mat dilateElement = cv::getStructuringElement(cv::MORPH_RECT, cv::Size(8, 8));

  cv::erode(thresh, thresh, erodeElement);
  cv::erode(thresh, thresh, erodeElement);

  cv::dilate(thresh, thresh, dilateElement);
  cv::dilate(thresh, thresh, dilateElement);
}
void
trackFilteredObject(int& x, int& y, cv::Mat cv::threshold, cv::Mat& cameraFeed) {

  cv::Mat temp;
  cv::threshold.copyTo(temp);
  // these two std::vectors needed for output of findContours
  std::vector<std::vector<cv::Point>> contours;
  std::vector<cv::Vec4i> hierarchy;
  // find contours of filtered image using openCV cv::findContours function
  cv::findContours(temp, contours, hierarchy, cv::RETR_CCOMP, cv::CHAIN_APPROX_SIMPLE);
  // use cv::moments method to find our filtered object
  double refArea = 0;
  bool objectFound = false;
  if(hierarchy.size() > 0) {
    int numObjects = hierarchy.size();
    // if number of objects greater than MAX_NUM_OBJECTS we have a noisy filter
    if(numObjects < MAX_NUM_OBJECTS) {
      for(int index = 0; index >= 0; index = hierarchy[index][0]) {

        cv::Moments moment = cv::moments((cv::Mat)contours[index]);
        double area = moment.m00;

        // if the area is less than 20 px by 20px then it is probably just noise
        // if the area is the same as the 3/2 of the image size, probably just a bad filter
        // we only want the object with the largest area so we safe a reference area each
        // iteration and compare it to the area in the next iteration.
        if(area > MIN_OBJECT_AREA && area < MAX_OBJECT_AREA && area > refArea) {
          x = moment.m10 / area;
          y = moment.m01 / area;
          objectFound = true;
          refArea = area;
        } else
          objectFound = false;
      }
      // let user know you found an object
      if(objectFound == true) {
        cv::putText(cameraFeed, "Tracking Object", cv::Point(0, 50), 2, 1, cv::Scalar(0, 255, 0), 2);
        // draw object location on screen
        drawObject(x, y, cameraFeed);
      }

    } else
      cv::putText(cameraFeed, "TOO MUCH NOISE! ADJUST FILTER", cv::Point(0, 50), 1, 2, cv::Scalar(0, 0, 255), 2);
  }
}
/**
 * @function processVideo
 */
void
processVideoBg(char* videoFilename) {
  // create the capture object
  cv::VideoCapture capture(videoFilename);
  if(!capture.isOpened()) {
    // cv::error in opening the video input
    cerr << "Unable to open video file: " << videoFilename << endl;
    exit(EXIT_FAILURE);
  }
  // cv::read input data. ESC or 'q' for quitting
  while((char)keyboard != 'q' && (char)keyboard != 27) {
    // cv::read the current frame
    if(!capture.read(frame)) {
      cerr << "Unable to cv::read next frame." << endl;
      cerr << "Exiting..." << endl;
      exit(EXIT_FAILURE);
    }
    // update the background model
    pMOG2->apply(frame, fgMaskMOG2);
    // get the frame number and cv::write it on the current frame
    stringstream ss;
    cv::rectangle(frame, cv::Point(10, 2), cv::Point(100, 20), cv::Scalar(255, 255, 255), -1);
    ss << capture.get(cv::CAP_PROP_POS_FRAMES);
    string frameNumberString = ss.str();
    cv::putText(frame, frameNumberString.c_str(), cv::Point(15, 15), cv::FONT_HERSHEY_SIMPLEX, 0.5, cv::Scalar(0, 0, 0));
    // show the current frame and the fg masks
    cv::imshow("Frame", frame);
    cv::imshow("FG Mask MOG 2", fgMaskMOG2);
    // get the input from the keyboard
    keyboard = cv::waitKey(30);
  }
  // delete capture object
  capture.release();
}
